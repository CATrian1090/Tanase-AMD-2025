{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CATrian1090/Tanase-AMD-2025/blob/main/TanaseAmd.ipynb)\n"
      ],
      "metadata": {
        "id": "zbIVS5wQKyfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasketch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsfI3LfF-YEG",
        "outputId": "801cd328-2ea2-4f73-8134-0a2c3c7a48bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasketch\n",
            "  Downloading datasketch-1.6.5-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.11/dist-packages (from datasketch) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasketch) (1.15.3)\n",
            "Downloading datasketch-1.6.5-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: datasketch\n",
            "Successfully installed datasketch-1.6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "USE_SAMPLE = True\n",
        "SAMPLE_SIZE = 10000\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from datasketch import MinHash, MinHashLSH\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "_5uNnGwpAElS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"XXXXXX\"\n",
        "os.environ['KAGGLE_KEY'] = \"XXXXXX\"\n",
        "\n",
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews\n",
        "!unzip -q \"*.zip\" -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghvlViWO9_Y5",
        "outputId": "84ba0203-4dc8-45e6-d8c4-7497998d8cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content\n",
            " 97% 1.03G/1.06G [00:07<00:00, 94.8MB/s]\n",
            "100% 1.06G/1.06G [00:07<00:00, 159MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv('Books_rating.csv')\n",
        "print(f\"Total reviews: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xVbmH6FBKPA",
        "outputId": "1bb47506-6ea2-4155-e0f0-617807bae5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reviews: 3000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove missing reviews and duplicates\n",
        "df = df.dropna(subset=['review/text'])\n",
        "print(f\"Reviews after removing missing: {len(df)}\")\n",
        "df = df.drop_duplicates(subset=['review/text'], keep='first')\n",
        "print(f\"Reviews after removing exact duplicates: {len(df)}\")\n",
        "\n",
        "# Sample data if specified\n",
        "if USE_SAMPLE:\n",
        "    df = df.sample(n=min(SAMPLE_SIZE, len(df)), random_state=42)\n",
        "    print(f\"Using sample of {len(df)} reviews\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2zTAJqDA_34",
        "outputId": "801351b5-b0c8-4b8e-c742-9cabc8bcda88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews after removing missing: 2999992\n",
            "Reviews after removing exact duplicates: 2062648\n",
            "Using sample of 10000 reviews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Preprocessing\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "def safe_tokenize(text):\n",
        "    try:\n",
        "        return word_tokenize(text)\n",
        "    except:\n",
        "        return text.split()\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return tuple()\n",
        "    text = text.lower().translate(translator)\n",
        "    tokens = safe_tokenize(text)\n",
        "    return tuple(sorted(set(lemmatizer.lemmatize(word) for word in tokens\n",
        "                          if word not in stop_words and len(word) > 2)))\n",
        "\n",
        "df['tokens'] = df['review/text'].apply(preprocess_text)\n",
        "df = df.drop_duplicates(subset=['tokens'], keep='first')\n",
        "df = df[df['tokens'].apply(len) >= 5].reset_index(drop=True)\n",
        "print(f\"Final reviews: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2a1w_HJ-A6D",
        "outputId": "b2002767-5b89-464c-f48c-ffc1798e18da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final reviews: 9983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MinHashing and LSH\n",
        "def create_minhash(tokens, num_perm=128):\n",
        "    \"\"\"Create MinHash signature for a tuple of tokens\"\"\"\n",
        "    minhash = MinHash(num_perm=num_perm)\n",
        "    for token in tokens:\n",
        "        minhash.update(token.encode('utf8'))\n",
        "    return minhash\n",
        "\n",
        "minhashes = []\n",
        "for tokens in tqdm(df['tokens'], desc=\"Computing MinHashes\"):\n",
        "    minhash = create_minhash(tokens, 128)\n",
        "    minhashes.append(minhash)\n",
        "\n",
        "lsh = MinHashLSH(threshold=0.5, num_perm=128)\n",
        "for i, minhash in enumerate(tqdm(minhashes, desc=\"Building LSH\")):\n",
        "    lsh.insert(str(i), minhash)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoCQwLUe-C5L",
        "outputId": "a5445210-5e31-452c-cf31-ce0073a408e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing MinHashes: 100%|██████████| 9983/9983 [00:20<00:00, 498.63it/s]\n",
            "Building LSH: 100%|██████████| 9983/9983 [00:01<00:00, 9449.08it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Finding Similar Pairs and Results\n",
        "def jaccard_similarity(tuple1, tuple2):\n",
        "    \"\"\"Calculate exact Jaccard similarity between two tuples (convert to sets)\"\"\"\n",
        "    set1 = set(tuple1)\n",
        "    set2 = set(tuple2)\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "print(\"Finding similar pairs...\")\n",
        "similar_pairs = []\n",
        "\n",
        "for i, minhash in enumerate(tqdm(minhashes, desc=\"Finding candidates\")):\n",
        "    candidates = lsh.query(minhash)\n",
        "    for candidate_str in candidates:\n",
        "        j = int(candidate_str)\n",
        "        if j > i:\n",
        "            # Calculate exact Jaccard similarity\n",
        "            similarity = jaccard_similarity(df.iloc[i]['tokens'], df.iloc[j]['tokens'])\n",
        "            if similarity > 0.0:\n",
        "                similar_pairs.append((similarity, i, j))\n",
        "\n",
        "# Sort by similarity and get top pairs\n",
        "similar_pairs.sort(reverse=True)\n",
        "top_similar_pairs = similar_pairs[:20]\n",
        "\n",
        "print(f\"\\nTop 20 Most Similar Review Pairs:\")\n",
        "print(\"=\" * 80)\n",
        "for rank, (similarity, i, j) in enumerate(top_similar_pairs, 1):\n",
        "    review1 = df.iloc[i]['review/text']\n",
        "    review2 = df.iloc[j]['review/text']\n",
        "\n",
        "    # Truncate reviews for display\n",
        "    review1_display = review1[:150] + \"...\" if len(review1) > 150 else review1\n",
        "    review2_display = review2[:150] + \"...\" if len(review2) > 150 else review2\n",
        "\n",
        "    print(f\"\\nRank {rank}: Jaccard Similarity = {similarity:.4f}\")\n",
        "    print(f\"Review {i}: {review1_display}\")\n",
        "    print(f\"Review {j}: {review2_display}\")\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8eZrCDY-GX6",
        "outputId": "b6267f2d-d238-406a-ff6f-3d6d001041fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding similar pairs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Finding candidates: 100%|██████████| 9983/9983 [00:00<00:00, 20033.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 Most Similar Review Pairs:\n",
            "================================================================================\n",
            "\n",
            "Rank 1: Jaccard Similarity = 0.5000\n",
            "Review 4719: Absolutely wonderful series of books. I can't wait to read the next one and then I start all over again!\n",
            "Review 4942: I really got into this book and can't wait for the next one. It was a wonderful story from start to finish.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 2: Jaccard Similarity = 0.5000\n",
            "Review 20: I really enjoyed this book; it's a must read\n",
            "Review 3357: My son is 7 and I read this book aloud to him. He really enjoyed the adventure!Great read!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 3: Jaccard Similarity = 0.4545\n",
            "Review 5546: Good book. great its free. It took me no time at all to get hooked. This is highly recommended. Great!\n",
            "Review 7188: It took some time for me to get into this book, but when I did...it was GREAT!!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 4: Jaccard Similarity = 0.4231\n",
            "Review 3953: I have been reading Danielle Steel for many years and I truly enjoyed this book. It was a wonderful love story. I read the reviews and decided to read...\n",
            "Review 9613: I found this book to be a wonderful love story. I loved it! I had read some of the reviews, but decided to read it for myself and boy was I glad I did...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 5: Jaccard Similarity = 0.4118\n",
            "Review 914: This book series by Lynn Austin was recommended to me by a friend. Once I've started reading these books it so hard to put them down. Each book is bet...\n",
            "Review 9793: This was a very good book hard to put down once I started reading it.. Excellent reading . I highly recommend it\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 6: Jaccard Similarity = 0.4000\n",
            "Review 2385: I read this book when I was 12 years old and it is still one of my all-time favorite books. I would recomend this book to any one, young or old.\n",
            "Review 4343: This book is the best I have read for many years. It is very up lifting. I would recomend this to every one to read.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 7: Jaccard Similarity = 0.4000\n",
            "Review 1494: If you are having a difficult time understanding exposure get this book, it is a great one!\n",
            "Review 7188: It took some time for me to get into this book, but when I did...it was GREAT!!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 8: Jaccard Similarity = 0.3571\n",
            "Review 3257: you will never look at this the same after reading this book. Everyone must read\n",
            "Review 3768: I thought this book was interesting and I liked it, but I never understood why everyone loves it so much. It's a good read, but not a must read.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 9: Jaccard Similarity = 0.3571\n",
            "Review 144: I use this book all the time. Very easy to read and understand. Now I'll always have it on my kindle.\n",
            "Review 2346: A good introduction to plyometrics. Easy to read and understand. I plan to use this book in my own training.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 10: Jaccard Similarity = 0.3500\n",
            "Review 5953: I read my first copy of My Family And Other Animals at the age of 13. Now, 16 years and 9 copies later, I still consider it one of my all time favouri...\n",
            "Review 7487: I read this book the first time when I was in high school. Forty some odd years later it still remains one of my most favorite books.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 11: Jaccard Similarity = 0.3333\n",
            "Review 162: This book is excellent for the advanced paleantologist for the narrative and photos are great. I would highly recommend it to anyone.\n",
            "Review 5748: This is a great book and I would highly recommend it to anyone going into counseling and also for some parents who struggle with their child's death.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 12: Jaccard Similarity = 0.3333\n",
            "Review 162: This book is excellent for the advanced paleantologist for the narrative and photos are great. I would highly recommend it to anyone.\n",
            "Review 4320: This is a great book about Airbus. The pictures are great. I would highly recommend for any airliner fanatics out there.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 13: Jaccard Similarity = 0.3043\n",
            "Review 1576: I recommend this book to anyone who loves adventures. I plan on reading this book time and time again. But first I must read the Lord of the rings.\n",
            "Review 8120: I enjoyed reading this book very much. I was not at all bored with it. This is a first time reading for me for this author. I would recommend this boo...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 14: Jaccard Similarity = 0.3000\n",
            "Review 6082: This is a great book! I loved all the magical creatures in the story and would recommend it to anyone who likes reading Harry Potter. If you didn't li...\n",
            "Review 8489: LOVED THIS BOOK AND RECEIVED IT IN GREAT SHAPE. WOULD RECOMMEND THIS BOOK TO ANYONE LOOKING FOR AN ADVENTURE!!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 15: Jaccard Similarity = 0.2941\n",
            "Review 4320: This is a great book about Airbus. The pictures are great. I would highly recommend for any airliner fanatics out there.\n",
            "Review 5748: This is a great book and I would highly recommend it to anyone going into counseling and also for some parents who struggle with their child's death.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 16: Jaccard Similarity = 0.2941\n",
            "Review 3130: This book is one of the best sci-fi books I have ever read ( I have read it at least five times). I recommend it to everyone\n",
            "Review 3972: ONE OF THE BEST BOOKS I'VE EVER READ!!!!!!! I love the Harry potter series!!! I love all J.K Rowling's books!!!!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 17: Jaccard Similarity = 0.2857\n",
            "Review 1494: If you are having a difficult time understanding exposure get this book, it is a great one!\n",
            "Review 5546: Good book. great its free. It took me no time at all to get hooked. This is highly recommended. Great!\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 18: Jaccard Similarity = 0.2857\n",
            "Review 1211: I read this book long ago but it still one of my fav. Its a very interesting book. If you like this kind of books you should give it a try.\n",
            "Review 1583: This was a good read. Surprisingly one of the most believable books that I have read in a long time. I recommend it for anyone who likes books that ar...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 19: Jaccard Similarity = 0.2632\n",
            "Review 1110: This book is an excellent source of stories for both children and adults. Well worth the price!\n",
            "Review 3127: This book provides an excellent technical and developmental history of the Panther. The author has obviously done his research on this vehicle. The bo...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 20: Jaccard Similarity = 0.2500\n",
            "Review 4869: I have read these books and they are exciting for me.They are too good and I want to read the next book fast. I can't wait to read it.\n",
            "Review 8515: I have really enjoyed the Andrew Mayhem series, can't wait to read the third book!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya9ADPDj9rQO",
        "outputId": "c48fb295-1222-43b0-bb05-b604a0c949cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to 'similar_review_pairs.csv'\n"
          ]
        }
      ],
      "source": [
        "# Save results to CSV\n",
        "results_df = pd.DataFrame(top_similar_pairs, columns=['similarity', 'index1', 'index2'])\n",
        "results_df['review1'] = results_df['index1'].apply(lambda x: df.iloc[x]['review/text'])\n",
        "results_df['review2'] = results_df['index2'].apply(lambda x: df.iloc[x]['review/text'])\n",
        "results_df.to_csv('similar_review_pairs.csv', index=False)\n",
        "print(f\"\\nResults saved to 'similar_review_pairs.csv'\")"
      ]
    }
  ]
}